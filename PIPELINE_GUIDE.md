# Cholera Prediction Pipeline - Quick Guide

## ğŸš€ **ONE COMMAND TO RUN EVERYTHING**

```bash
python run_pipeline.py
```

That's it! This runs the complete pipeline automatically.

---

## ğŸ“‹ **What It Does**

The master script (`run_pipeline.py`) runs these steps in order:

1. **Extract Environmental Data** (~15-20 min per LGA)
   - Weather, climate, vegetation data from Google Earth Engine
   - Can be skipped if data already exists

2. **Extract Socioeconomic Data** (~1-2 min)
   - Relative Wealth Index (RWI)
   - Population estimates

3. **Merge All Data** (~2-3 min)
   - Combines environmental + socioeconomic + epidemiological data
   - Creates complete dataset for modeling

4. **Train Models & Predict** (~3-5 min)
   - Trains 4 machine learning models
   - Generates predictions and visualizations
   - Creates maps and charts

5. **Generate PDF Report** (~1 min)
   - Comprehensive report with all results
   - Professional maps, charts, and tables

---

## âš™ï¸ **Interactive Options**

When you run `python run_pipeline.py`, it will ask:

```
Skip environmental extraction? (y/n):
```

- **Type 'n'** (No) - Run full pipeline including environmental extraction
- **Type 'y'** (Yes) - Skip environmental extraction (faster, if data exists)

---

## â±ï¸ **Time Estimates**

| Scenario | Time Required |
|----------|---------------|
| **Full pipeline (new data)** | 2-4 hours |
| **Skip environmental extraction** | ~10 minutes |
| **Re-run with same data** | ~5 minutes |

---

## âœ… **Prerequisites Check**

The script automatically checks for:
- âœ… `Data/LGA.shp` - Shapefile
- âœ… `Data/rwi.tif` - Wealth index raster
- âœ… `Data/*Cholera*Line*list*.xlsx` - Epidemiological data
- âœ… `keys/service_account.json` - GEE credentials

---

## ğŸ“ **Outputs Generated**

After successful run:

```
predictions/
â”œâ”€â”€ Cholera_Prediction_Report_Complete.pdf  â­ Main deliverable
â”œâ”€â”€ cholera_predictions.xlsx
â”œâ”€â”€ future_predictions_12weeks.xlsx
â”œâ”€â”€ cholera_maps.png
â””â”€â”€ analysis_charts.png

merged_data/
â””â”€â”€ cholera_merged_dataset.csv

model_output/
â”œâ”€â”€ best_model.pkl
â”œâ”€â”€ scaler.pkl
â””â”€â”€ model_results.csv
```

---

## ğŸ”„ **When to Re-run**

### New Cases (Same LGAs)
```bash
python run_pipeline.py
# Choose 'y' to skip environmental extraction
# Time: ~10 minutes
```

### New LGAs or States
```bash
python run_pipeline.py
# Choose 'n' to run environmental extraction
# Time: 2-4 hours (depends on # of LGAs)
```

### Quick Report Update
```bash
python 04_generate_pdf_report.py
# Time: ~1 minute
```

---

## ğŸ› **If Something Fails**

The pipeline will:
1. Show which step failed
2. Display the error message
3. Tell you the exact script that failed

You can then:
- Fix the error
- Run the pipeline again (it will restart from beginning)
- OR run individual scripts manually:

```bash
# Run specific step
python 01_extract_socioeconomic_data.py
python 02_merge_all_data.py
# etc.
```

---

## ğŸ’¡ **Pro Tips**

### 1. First Time Setup
```bash
# Check everything is ready
python run_pipeline.py
# It will tell you if anything is missing
```

### 2. Regular Updates
```bash
# Update epi data Excel file
# Then run:
python run_pipeline.py
# Skip environmental extraction for speed
```

### 3. Force Fresh Extraction
```bash
# Edit run_pipeline.py, line 96:
skip_environmental_extraction = False  # Forces full extraction

# Then run:
python run_pipeline.py
```

### 4. Run Overnight
```bash
# For large datasets, run overnight:
nohup python run_pipeline.py > pipeline.log 2>&1 &
# Check progress: tail -f pipeline.log
```

---

## ğŸ“Š **Progress Monitoring**

The script shows:
- âœ… Step completion status
- â±ï¸ Time elapsed per step
- ğŸ“ Last 5 lines of output from each script
- ğŸ¯ Final summary with all outputs

Example output:
```
================================================================================
STEP 3/5: Merge Environmental + Socioeconomic + Epidemiological Data
================================================================================
Running: 02_merge_all_data.py
Started: 10:30:15
âœ… SUCCESS - Completed in 2.3 minutes

Last 5 lines of output:
   Total records: 3156
   LGAs: 6
   Date range: 2014-10-27 to 2024-11-24
   Total cases: 513
   Output: merged_data/cholera_merged_dataset.csv
```

---

## ğŸ¯ **Quick Reference**

| Command | Purpose | Time |
|---------|---------|------|
| `python run_pipeline.py` | Run complete pipeline | Varies |
| `python extract_weekly_checkpoint.py` | Just environmental data | ~15 min/LGA |
| `python 02_merge_all_data.py` | Just merge data | ~2 min |
| `python 03_train_predict_visualize.py` | Just train & predict | ~3-5 min |
| `python 04_generate_pdf_report.py` | Just generate PDF | ~1 min |

---

## ğŸ“ **Support**

If the pipeline fails:
1. Read the error message carefully
2. Check prerequisites are all present
3. Verify data format matches examples
4. Review individual script if needed
5. Check `pipeline.log` if running in background

---

## ğŸ‰ **Success Indicators**

Pipeline completed successfully if you see:
```
================================================================================
âœ… PIPELINE COMPLETED SUCCESSFULLY!
================================================================================
Total time: 10.5 minutes
Completed: 2025-10-17 10:45:30
```

And these files exist:
- âœ… `predictions/Cholera_Prediction_Report_Complete.pdf`
- âœ… `predictions/future_predictions_12weeks.xlsx`
- âœ… `model_output/best_model.pkl`

---

**Last Updated:** 2025-10-17
